# 

# 频繁项集挖掘算法的研究与实现

## 背景
随着数据库技术的迅速发展以及数据库管理系统的广泛应用，人们积累的数据越来越多.但是目前的数据库系统可以高效地实现数据的存取、查询、统计等功能，却不能发现数据中存在的关联关系，无法根据现有数据为人们进行决策支持、预测发展趋势等，传统的数据分析工具以及我们的大脑更无力应对如此庞大的数据规模，于是出现了“数据爆炸但知识贫乏”的现象。


## 意义

与传统计数相比，数据挖掘技术可以帮助人们更有效的利用利用海量数据中存在的价值。而频繁项集挖掘作为数据挖掘的重要内容之一，已经得到了很快的发展，并且应用到了各行各业，如金融、互联网、电商、医学等领域。它是指从大量数据中挖掘出频繁模式，从而发现可能存在的某些关联，通过分析这些关联关系可以帮我们预测将会发生的某些事情。因此，对频繁项集挖掘技术的研究具有重要的意义。


## 相关概念

- 项集： 项的集合称为项集，包含k个项的项集称为k-项集。
- 频繁项集： 如果项集的支持度满足预定义的最小支持度阈值，则称它为频繁项集。
- 关联规则：关联规则是形如 $X->Y$ 的蕴含式，它表示项集X代表的事件发生时，导致事件Y也以某一概率发生。
- 置信度： 规则 $X->Y$ 的置信度是指包含项集X的事务中同时包含Y的概率。
- 支持度: 项集X的支持度是指包含项集X的事务在总数据集中所占的比例

## 算法简介

频繁项集挖掘算法主要分为两类：一类是以Apriori算法为代表的产生候选项集的挖掘算法，另一类是以Fp-growth算法为代表的不产生候选项集的算法。

> Apriori算法采用迭代的方法，每迭代一次就需要扫描一次数据集，产生相应的候选项集，统计出每一个候选项的支持度，然后筛选出频繁项。

> Fp-growth算法采用递归的方式，先扫描一遍数据集，统计出每个元素出现的次数，然后第二次扫描数据集，将数据以树形结构存储在内存中，接下来就是从树的叶子向根节点递归挖掘频繁项集。

### Apriori算法原理

Apriori定律： 
1. 一个频繁项集所包含的子集都是频繁项集。
2. 非频繁项集的父集都是非频繁项集


Apriori算法使用广度优先的方法，从候选项集中筛选频繁项，再有频繁项集自我连接产生候选项，如此迭代下去就挖掘出了所有的频繁项集，总结该过程可以分为连接和剪枝两个步骤，以下是具体过程：


|TId| Items|
|--|--|
|01 | L1，L2，L5|
|02 | L2，L4 |
|03 | L2，L4|
|04 | L1，L2，L3，L4，L5，L6，L7|
|05 | L1，L2，L4|
|06 | L1，L3|
|07 | L2，L3|
|08 | L1，L3|
|09 | L1，L2，L3，L4，L5|
|10 | L1，L2，L3，L4|

> 令 $support = 0.3, connfigdence =0.7 $,这两个参数是频繁项集挖掘算法中最重要的两个参数，实际应用中可以进行适当的调整以适应算法。首次遍历数据集，计算出每项的支持度，生成候选项集C1，如表所示。 


#### 第1轮
候选1项集

|L1| L2| L3 | L4 |L5 | L6 | L7|
|--|--|--|--|--|--|--|
|7 | 8 | 7| 5|3|1|1|

频繁1项集
|L1| L2| L3 | L4 |L5 | 
|--|--|--|--|--|
|7 | 8 | 7| 5|3|

Apriori算法原理
- 连接：将频繁K-1项集两两连接，生成候选K项集。要求两个项集有K-2个相同项，然后与两个不同项合并，构成K项集。
- 剪枝：若候选项集中某一项中含有非频繁子集，则该项不满足频繁项集的条件，删除该项。

#### 第2轮

 候选2项集,

|Item| Support|
|--|--|
|{L1,L2} | 5|
|{L1,L3} | 5|
|{L1,L4} | 4|
|{L1,L5} | 3|
|{L2,L3} | 5|
|{L2,L4} | 5|
|{L2,L5} | 3|
|{L3,L4} | 3|
|{L3,L5} | 2|
|{L4,L5} | 2|

频繁2项集
|Item| Support|
|--|--|
|{L1,L2} | 5|
|{L1,L3} | 5|
|{L1,L4} | 4|
|{L1,L5} | 3|
|{L2,L3} | 5|
|{L2,L4} | 5|
|{L2,L5} | 3|
|{L3,L4} | 3|

#### 第三轮

 频繁3项集

|Item| Support|
|--|--|
|{L1,L2,L3} | 3|
|{L1,L2,L4} | 3|
|{L1,L2,L5} | 3|
|{L1,L3,L4} | 3|
|{L2,L3,L4} | 3|

#### 第4轮

频繁4项集
|Item| Support|
|--|--|
|{L1,L2,L1,L2} | 3|


> 注：{L1，L2，L5}分别与{L1，L3，L4}和{L2，L3，L4}不满足连接条件。


### Fp-growth算法原理

Fp-growth算法包含两个部分：
（1）构建Fp-tree：首次遍历数据集，统计每个元素的支持度计数min_support，剔除掉支持度小于min_support的非频繁项，对余下的频繁项根据min_support由大到小排序得到项头表；再次遍历数据集，把每一条数据参考项头表中的次序添加到Fp树上。
（2）挖掘频繁模式：构造好Fp-tree后，就可以通过这棵树发掘出全部频繁项集。首先从项头表排在最后的节点开始，在Fp-tree中自底向上，找出该节点的所有前缀路径，构成该节点的条件模式基，通过条件模式基构造条件Fp-tree，对该树中的节点进行全排列组合，就可以得到频繁项集。重复地迭代这两个步骤，到Fp树中只剩下一个叶节点时结束。


|TId| Items|
|--|--|
|01 | L1，L2，L5|
|02 | L2，L4 |
|03 | L2，L4|
|04 | L1，L2，L3，L4，L5，L6，L7|
|05 | L1，L2，L4|
|06 | L1，L3|
|07 | L2，L3|
|08 | L1，L3|
|09 | L1，L2，L3，L4，L5|
|10 | L1，L2，L3，L4|


元素`支持度`统计表，


|L1| L2| L3 | L4 |L5 | L6 | L7|
|--|--|--|--|--|--|--|
|7 | 8 | 7| 5|3|1|1|

项头表

频繁1项集
|L1| L2| L3 | L4 |L5 | 
|--|--|--|--|--|
|7 | 8 | 7| 5 | 3 |
|null | null | null| null|null|



|TId| Items|
|--|--|
|01 | L2，L1，L5|
|02 | L2，L4 |
|03 | L2，L3|
|04 | L2，L1，L3，L4，L5 |
|05 | L2，L1，L4|
|06 | L1，L3|
|07 | L2，L3|
|08 | L1，L3|
|09 | L2，L1，L3，L4，L5|
|10 | L2，L1，L3，L4|

#### 生成 $Fp$ 树

|Item| Support|
|--|--|
|L2 | 9|
|L2 | 7|
|L2 | 7|
|L2 | 5|
|L2 | 5|




## 其他算法介绍

**Apriori算法简介**

Apriori算法是最经典的频繁项集挖掘算法，其目的是挖掘数据集中项与项之间的关系，整个工作流程由两个阶段构成，首先是发掘出频繁模式，然后由频繁项计算关联规则。该算法的核心内容就是找出数据集中的频繁模式，整个算法过程中该步骤占大部分时间，所以该算法的效率由挖掘频繁项集的效率所决定的，衡量该算法的优劣就看第一个步骤是否高效。
Apriori算法由两个重要定律，也是该算法的核心思想：

（1）一个频繁项集所包含的子集都是频繁项集。我们假设有频繁项集{I1，I2，I3}，支持度为S，最小支持度为min_support，由于它是频繁的所以S>=min_support，因为I1、I2、I3同时出现的概率大于等于min_support，并且他们自由组合形成的子集出现的频率大于等于S，所以，一个频繁项集所包含的子集也频繁的。

（2）若一个项集不是频繁项集，那么它的的父集也一定不是频繁的。我们假设项集{I1}是非频繁项集，所以整个数据集中I1出现的频率小于min_support，所以任何包含I1的项集比如{I1、I2、I3}等出现的频率也都小于min_support，所以他们都不是频繁项集。

有了以上两个重要思想，我们就可以扫描数据集判断哪些项集是频繁的，首先先判断一项集，筛选出频繁一项集后进行随机地两两组合，构成候选的二项集，然后继续使用该思想筛选出频繁二项集，往复迭代下去，直至不能组合出新的候选项集为止，至此所有的频繁项集均已产生，需要特别强调的是，在相同的数据集下，min_support的值不同所产生的频繁项集也是不同的。


